_target_: lexikanon.pipes.tokenize.extract_tokens
tokenizer: simple
num_workers: 1
batched: true
batch_size: 1000
token_col: tokens
extracted_col: extracted_tokens
nouns_only: false
postags: null
stop_postags: null
strip_pos: null
postag_delim: null
postag_length: null
remove_columns: null
load_from_cache_file: true
num_heads: 1
num_tails: 1
verbose: false
